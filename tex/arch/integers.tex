\section{Integers}

\label{sec:arch:int}

\subsection{Binary numbers and modular arithmetic}

\label{subsec:arch:bin}

Computers must operate on finite values.  This fact limits the maximum values of
numbers they can represent and manipulate.  The \textit{word size}\footnotemark
of a computer architecture determines the natural unit of data of the
instruction set and limits the size of numbers directly accessible.  Early
computers had 8-bit words and several word sizes have existed throughout
history, but common sizes are now 32 and 64 bits.

\footnotetext{
    Used here \textit{stricto sensu}, in contrast to the alternative definition
    of ``word'' as the word size of a particular ancestor of the architecture
    that is now maintained for backwards compatibility (e.g.  ``16-bit word'' in
    x86).}

A binary number with $n$ bits, or \textit{binary digits}, has $2^n$ possible
values.  Table \ref{tbl:arch:integers:bits} shows the common word sizes and the
number of integer values they can represent.  An 8-bit byte can represent two
hundred and fifty six distinct values, while that number is approximately sixty
five thousand, four billion, and eighteen quintillion for 16-, 32-, and 64-bit
numbers, respectively\footnotemark.

\footnotetext{
    Note that the progression of powers in radix 2 whose exponents are multiples
    of 10 is close to those in radix 10 whose exponents are multiples of 3,
    thus:
    \begin{alignat*}{11}
        2^{10} &\approx 10^3    & \quad & \delta\; &= 0.0234375 & \qquad &
        2^{40} &\approx 10^{12} & \quad & \delta\; &= 0.0905053 \\
        2^{20} &\approx 10^6    & \quad & \delta\; &= 0.0463257 & \qquad &
        2^{50} &\approx 10^{15} & \quad & \delta\; &= 0.1118216 & \qquad
        \ldots \\
        2^{30} &\approx 10^9    & \quad & \delta\; &= 0.0686774 & \qquad &
        2^{60} &\approx 10^{18} & \quad & \delta\; &= 0.1326383 \\
    \end{alignat*}
    \vspace{-\baselineskip}
}

\begin{figure}[ht]
    \centering
    \begin{tabular}{ccc}
        bits ($n$) & values ($2^n$) & digits ($\log_{10} 2^n$) \\
        \hline
         8 & 256 & 3 \\
        16 & 65,536 & 5 \\
        32 & 4,294,967,296 & 10 \\
        64 & 18,446,744,073,709,551,616 & 20 \\
    \end{tabular}
    \caption{Number of possible values for an \texttt{n}-bit integer}
    \label{tbl:arch:integers:bits}
\end{figure}

This finiteness means operations eventually exceed the minimum and/or maximum
values --- these events are called \textit{underflow} and \textit{overflow},
respectively.  \textit{Overflow exceptions}\footnotemark are one possible
mechanism to detect and handle them: a signal is generated by the hardware as a
result of the execution of the offending instruction.  This is, however, an
expensive process.

\footnotetext{
    Meaning a \emph{hardware} exception/fault in this case, not the
    similar software concept with the same name.}

More importantly, some of the most fundamental mathematical properties of
operations are not retained: \texttt{(x + x) - x} is no longer equal to
\texttt{x + (x - x)}.  The sum in the former can overflow, while the latter will
always equal \texttt{x}; i.e. associativity is not preserved\footnotemark.

\footnotetext{
    Far from a theoretical point, a very similar computation was the source of a
    problem in one of the most famous algorithms (and algorithm books), the
    binary search in Jon Bentley's \textit{Programming Pearls} (v. section
    \secrefpar{sec:algo:bsearch}).}

Another option in the case of integers is to perform \textit{modular
arithmetic}: operations are executed \emph{modulo} the total number of
representable values.  For a binary number with $n$ bits, operations are
performed \emph{modulo} $2^n$.  Modular arithmetic preserves all of the ordinary
mathematical properties of operations:

\begin{alignat*}{5}
    x + y \quad &\equiv_{\bmod n} &\quad& y + x
    && \qquad \text{additive commutativity}
    \\
    (x + y) + z \quad &\equiv_{\bmod n} &\quad& x + (y + z)
    && \qquad \text{additive associativity}
    \\
    x + 0 \quad &\equiv_{\bmod n} &\quad& x
    && \qquad \text{additive unit}
    \\\\
    x + (-x) \quad &\equiv_{\bmod n} &\quad& 0
    && \qquad \text{additive inverse}
    \\
    -(-x) \quad &\equiv_{\bmod n} &\quad& x
    && \qquad \text{cancellation}
    \\\\
    x \times y \quad &\equiv_{\bmod n} &\quad& y \times x
    && \qquad \text{multiplicative commutativity}
    \\
    (x \times y) \times z \quad &\equiv_{\bmod n} &\quad& x \times (y \times z)
    && \qquad \text{multiplicative associativity}
    \\
    x \times 1 \quad &\equiv_{\bmod n} &\quad& x
    && \qquad \text{multiplicative unit}
    \\\\
    x \times (y + z) \quad &\equiv_{\bmod n} &\quad& x \times y + x \times z
    && \qquad \text{distributivity}
    \\
    x \times 0 \quad &\equiv_{\bmod n} &\quad& 0
    && \qquad \text{annihilation}
    \\
\end{alignat*}

\subsubsection{Addition}

The addition of bounded integers can be defined in terms of its inputs --- the
\textit{augend} and the \textit{addend} --- and its outputs --- the \textit{sum}
and the \textit{carry}.  In the case of one-digit binary numbers with modular
arithmetic, the sum is equivalent to an \textit{exclusive or} operation
(\textit{xor}, also denoted as $\oplus$ for that reason).  Similarly, the carry
is equivalent to an \textit{and} operation (also denoted as $\cdot$).  The
resulting equations can be represented in a truth table and encoded in a logic
circuit (figure \ref{fig:arch:half_adder}).

\begin{figure}[ht]
    \centering
    \begin{subfigure}[h]{0.25\textwidth}
        \begin{tabular}{c}
            \begin{lstlisting}[style=c]
s = au ^ ad;
c = au & ad;
            \end{lstlisting}
        \end{tabular}
    \end{subfigure}
    \begin{subfigure}[h]{0.3\textwidth}
        \begin{tabular}{cc|cc}
            \multicolumn{2}{c|}{Input} &
            \multicolumn{2}{c}{Output} \\
            AU & AD & S & C \\
            \hline
            0 & 0 & 0 & 0 \\
            0 & 1 & 1 & 0 \\
            1 & 0 & 1 & 0 \\
            1 & 1 & 0 & 1 \\
        \end{tabular}
    \end{subfigure}
    \begin{subfigure}[h]{0.4\textwidth}
        \input{arch/integers/half_adder.tex}
    \end{subfigure}
    \caption{One-digit binary half adder}
    \label{fig:arch:half_adder}
\end{figure}

This circuit, a \textit{half adder}, can be combined with an external carry
input to form a \textit{full adder} (figure \ref{fig:arch:adder}).  Multiple
full adders can then be connected in sequence to produce an adder for an
arbitrary number of digits, a \textit{ripple-carry adder}.

\begin{figure}[ht]
    \centering
    \hfill
    \begin{subfigure}[h]{0.35\textwidth}
        \begin{tabular}{ccc|cc}
            \multicolumn{3}{c|}{Input} &
            \multicolumn{2}{c}{Output} \\
            AU & AD & C$_{in}$ & S & C \\
            \hline
            0 & 0 & 0 & 0 & 0 \\
            0 & 1 & 0 & 1 & 0 \\
            1 & 0 & 0 & 1 & 0 \\
            1 & 1 & 0 & 0 & 1 \\
            \hline
            0 & 0 & 1 & 1 & 0 \\
            0 & 1 & 1 & 0 & 1 \\
            1 & 0 & 1 & 0 & 1 \\
            1 & 1 & 1 & 1 & 1 \\
        \end{tabular}
    \end{subfigure}
    \hfill
    \begin{subfigure}[h]{0.5\textwidth}
        \input{arch/integers/adder.tex}
    \end{subfigure}
    \caption{One-digit binary adder}
    \label{fig:arch:adder}
\end{figure}

It is important to note that the result of the addition of two binary numbers
with $n$ bits requires only a single extra bit to be represented.  This is
easily demonstrated since the maximum resulting value is the sum of the maximum
value ($2^n - 1$) with itself:

\begin{align*}
    s        &=   max + max \\
             &=   2^n - 1 + 2^n - 1 \\
             &=   2 \times 2^n - 2 \\
             &=   2^{n + 1} - 2 \\\\
    \log_2 s &\le n + 1 \\
\end{align*}

In an \textit{arithmetic logic unit} (ALU), this means the same type of register
can be used to store the result along with the final carry output of the final
adder in the multi-digit addition circuit.  This carry output is connected to
the \textit{carry flag}, which can be used in instructions following the
addition, including other additions, where it serves as the input carry to the
first adder.  One example of its usage is to implement addition of numbers
larger than the maximum supported integer type: a pair of arrays of numbers can
be summed in sequence, with each iteration adding the carry flag to the next
(more significant) group of digits.

Since integer operations are modulo $2^n$, where $n$ is the word size and the
size of the ALU registers, simply truncating the result to the register size ---
i.e. ignoring the carry --- effects modular arithmetic.  Listing
\ref{lst:arch:add_mod} shows examples of addition with 4-bit integers.

\begin{figure}[ht]
    \begin{lstlisting}[
        caption=Addition with modular arithmetic,
        label=lst:arch:add_mod,
        xleftmargin=0.2\textwidth,
    ]
 0b0100 = 4    0b0111 = 7      0b1100 = 12
+0b0011 = 3   +0b0001 = 1     +0b0111 =  7
-------       -------         -------
      1            10 carry         1
     1            10  carry        1
    1            10   carry      10   carry
-------       -------           10    carry
 0b0111 = 7    0b1000 = 8     -------
                              0b10011 = 19
                              0b1     = 19 / 16
                                      = 19 >> 4
                                      = 1 (carry flag)
                              0b 0011 = 19 % 16
                                      = 19 & 0xf
                                      = 3
    \end{lstlisting}
\end{figure}

\begin{aside}
    The simple concatenation of instances of the adder in figure
    \ref{fig:arch:adder} is not the most efficient configuration for multi-digit
    addition.  This is because the computation of the carry bit for each
    successive digit must wait for the computation of the previous, serializing
    the entire process.

    Alternative designs for the half/full adders allow faster implementations
    than a naive concatenation of adders.  This is achieved by forwarding the
    carry bit to subsequent digits as soon as possible based on the input.
    These designs are called \textit{carry-lookahead adders} for this reason.
    Their basic mode of operation is to group a number of pairs of input digits
    (e.g. 4) under a \textit{lookahead unit}.  The result of the addition
    (\textit{S} in the figure) of each pair is calculated and propagated to the
    unit.  Once it receives its carry input, the unit can immediately calculate
    the carry for the entire group and send it to the next unit, so that it does
    not have to wait for the carry to go through each digit in the group to be
    propagated.
\end{aside}

\subsubsection{Subtraction}

\label{subsubsec:arch:sub}

Subtraction is in many ways analogous to addition: a \textit{minuend},
\textit{subtrahend}, and a \textit{borrow} are combined to produce the
\textit{difference} and the subsequent borrow for each bit, and the last output
borrow affects the carry flag (also called the \textit{borrow flag}.  In fact,
because of modular arithmetic, the computation of the difference for one-digit
binary numbers is exactly the same as that of the sum (figure
\ref{fig:arch:half_subtractor}).  Computing the borrow also uses an \textit{and}
gate but requires an extra \textit{not} gate.  Figure \ref{fig:arch:subtractor}
shows the full subtractor\footnotemark.

\footnotetext{
    Some architectures take advantage of the arithmetic properties described in
    section \secref{subsec:arch:ones_twos_comp} to implement addition and
    subtraction using the same circuit with just a few extra switches to
    pre-process the input values.}

\begin{figure}[ht]
    \centering
    \begin{subfigure}[h]{0.3\textwidth}
        \begin{tabular}{cc|cc}
            \multicolumn{2}{c|}{Input} &
            \multicolumn{2}{c}{Output} \\
            M & S & D & B \\
            \hline
            0 & 0 & 0 & 0 \\
            0 & 1 & 1 & 1 \\
            1 & 0 & 1 & 0 \\
            1 & 1 & 0 & 0 \\
        \end{tabular}
    \end{subfigure}
    \begin{subfigure}[h]{0.3\textwidth}
        \input{arch/integers/half_subtractor.tex}
    \end{subfigure}
    \caption{One-digit binary half subtractor}
    \label{fig:arch:half_subtractor}
\end{figure}

\begin{figure}[ht]
    \centering
    \begin{subfigure}[h]{0.3\textwidth}
        \begin{tabular}{ccc|cc}
            \multicolumn{3}{c|}{Input} &
            \multicolumn{2}{c}{Output} \\
            M & S & B$_{in}$ & D & B \\
            \hline
            0 & 0 & 0 & 0 & 0 \\
            0 & 1 & 0 & 1 & 1 \\
            1 & 0 & 0 & 1 & 0 \\
            1 & 1 & 0 & 0 & 0 \\
            \hline
            0 & 0 & 1 & 1 & 1 \\
            0 & 1 & 1 & 0 & 1 \\
            1 & 0 & 1 & 0 & 0 \\
            1 & 1 & 1 & 1 & 1 \\
        \end{tabular}
    \end{subfigure}
    \begin{subfigure}[h]{0.65\textwidth}
        \input{arch/integers/subtractor.tex}
    \end{subfigure}
    \caption{One-digit binary subtractor}
    \label{fig:arch:subtractor}
\end{figure}

Listing \ref{lst:arch:sub_mod} shows examples of subtraction with 4-bit
integers.  As is the case with addition with carry, subtraction with borrow of
binary numbers has the peculiarity that borrowing can also be seen as a bit
flip, as \texttt{1} is the maximum value a digit can have.  Thus, when 1 is
subtracted from a binary number, all lower \texttt{0}s are turned into
\texttt{1}s and the lower \texttt{1} is turned into \texttt{0}.  In other words,
all bits up to and including the lowest \texttt{1} are flipped.  If there is no
bit set --- i.e.  the minuend is zero --- all bits are turned into
\texttt{1}s\footnotemark.  Digits above the lower \texttt{1} are unchanged.

\begin{figure}[ht]
    \begin{lstlisting}[
        caption=Subtraction with modular arithmetic,
        label=lst:arch:sub_mod,
        xleftmargin=0.2\textwidth,
    ]
 0b0111 = 7    0b1100 = 12      0b0010 = 2
-0b0011 = 3   +0b0001 =  1     -0b0100 = 4
-------       -------          -------
      0             1 borrow         0
     0             1                1
    1             0                1   borrow
-------          1                1
 0b0100 = 4   -------          -------
               0b1011 = 11     0b11110 = 30
                               0b1     = 30 / 16
                                       = 30 >> 4
                                       = 1 (borrow flag)
                               0b 1110 = 30 % 16
                                       = 30 & 0xf
                                       = 14
    \end{lstlisting}
\end{figure}

\footnotetext{
    The final value of course depends on the number representation of a
    particular system.  In abstract terms, the \texttt{1}s extend to infinity.
    In a real and finite ALU, all bits in the output register are set to
    \texttt{1}, effecting modular arithmetic.  The carry flag is also set,
    allowing the CPU to handle this underflow case in a variety of ways.}

\subsection{One's and two's complement}

\label{subsec:arch:ones_twos_comp}
