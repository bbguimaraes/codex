\section{Sorting}

\subsection{Ordering}
\label{subsec:algo:ordering}

\begin{description}
    \item[Partial order]
        is an ordering relation which cannot be used to order all elements of a
        set.
    \item[Weak partial order]
        is a partial ordering relation which is reflexive, i.e. for relation
        $R$, $\forall x \in X, x R x$.  The \textit{less-than-or-equal} relation
        ($\leq$) is weak since $x \leq x$.
    \item[Strong partial order]
        is a partial ordering relation which is irreflexive, i.e. for relation
        $R$, $\forall x \in X, \neg(x R x)$.  The \textit{less-than} relation
        ($<$) is strong since $\neg(x < x)$.
    \item[Total order]
        is an ordering relation where every element can be classified as
        preceding or succeeding every other element.
\end{description}

\begin{aside}
    Examples of weak partial orders that occur commonly in programming are:
    \begin{itemize}
        \item
            The edges of a directed acyclic graph.  Ancestors in unrelated
            hierarchies have no relation to each other.
        \item
            The \textit{happens-before} relation in memory ordering operations
            (v.  \secrefpar{sec:conc:atomic}).  Two operations that happen
            before a third are unsequenced with respect to each other.
    \end{itemize}
\end{aside}

Note that (several) total orders can always be established for finite partial
orders:

\begin{itemize}
    \item
        A particular topological order of a directed acyclic graph establishes a
        total order from the partial order described by its edges.
    \item
        A particular sequence of operations under sequential consistency
        establishes a total order from the partial order of memory ordering
        operations.
\end{itemize}

\subsection{Equivalence}

In mathematics and computer science, two concepts are involved in determining
the fundamental relation between values of a given type: \textit{equivalence}
and \textit{equality}.  Equivalence (often represented as $\sim$ or $\equiv$) is
described mathematically as a binary relation that is:

\begin{description}
    \item[Reflexive] $x \sim x$
    \item[Symmetric] $x \sim y \implies y \sim x$
    \item[Transitive] $(x \sim y) \land (y \sim z) \implies x \sim z$
\end{description}

Any relation which satisfies these properties is an \textit{equivalence
relation}.  Equality is the canonical equivalence relation: $x$ and $y$ are
\textit{equal} iff they have the same value.  Equivalence relations are
interesting in both mathematics and computer science because they still apply to
types which may not have a strict equality relation: it is a more general
relation.

In practical terms, specifically in the context of sorting and searching
algorithms, a \textit{strict partial order} (i.e. irreflexive) is sufficient for
their implementation.  This allows these algorithms to be applied to types which
do not have a concept of equality and simplifies their interface, since a single
relation can be used for all operations instead of two.  For example, the
\texttt{std::sort} and \texttt{std::binary\_search} algorithms (to list a few)
in the C++ standard library define their semantics in terms of an equivalence
relation, for which \texttt{std::less} --- a generic version of the \texttt{<}
operator --- is the canonical implementation, establishing the following
definitions:

\begin{description}
    \item[Equality]
        \texttt{x == y}, as dictated by \texttt{operator==}
    \item[Equivalence]
        \texttt{!(x < y) \&\& !(y < x)}, as dictated by \texttt{operator<}
\end{description}

% TODO https://en.wikipedia.org/wiki/Insertion_sort
% TODO https://en.wikipedia.org/wiki/Bubble_sort
% TODO https://en.wikipedia.org/wiki/Merge_sort
% TODO https://en.wikipedia.org/wiki/Heapsort
% TODO https://en.wikipedia.org/wiki/Bogosort
% TODO https://en.wikipedia.org/wiki/Bucket_sort
% TODO https://en.wikipedia.org/wiki/Radix_sort

\subsection{Selection sort}

\begin{figure}[p]
    \centering
    \lstinputlisting[
        style=c++,
        firstline=7,
        caption={Selection sort},
        label={lst:algo:selection},
    ]{algo/sort/selection.cpp}
    \vspace{2\baselineskip}
    \input{algo/sort/selection.tex}
    \caption{Selection sort}
    \label{fig:algo:selection}
\end{figure}

One of the simplest sorting algorithms is \textit{selection sort}, which works
by progressively sorting the left side of the range one element at a time
(figure \ref{fig:algo:selection}).  In each iteration, the minimum value in the
unsorted portion is found (\emph{selected}) and placed at the beginning,
increasing the size of the sorted range by one element.  When all positions of
the range have gone through this procedure, the range is sorted.

The implementation of the algorithm follows naturally from this description
(listing \ref{lst:algo:selection}).  In each iteration, the beginning of the
range is guaranteed to already be sorted.  The minimum element of the rest of
the unsorted range is found, swapped with the element at the beginning of the
range, guaranteeing that the range is now partitioned with respect to the
selected element.

\subsection{Quick sort}

\begin{figure}[p]
    \centering
    \lstinputlisting[
        style=c++,
        firstline=8,
        lastline=15,
        caption={Quick sort},
        label={lst:algo:quick},
    ]{algo/sort/quick.cpp}
    \vspace{2\baselineskip}
    \input{algo/sort/quick.tex}
    \caption{Quick sort}
    \label{fig:algo:quick}
\end{figure}

Quick sort\footnote{\cite{Hoare1962}} is based on the familiar method of binary
recursion.  The range to be sorted is partitioned in two based on whether
elements are lesser or greater than a reference element (the \textit{pivot}).
This places that element at its correct position in the sorted range.  The
process is then repeated for the sub-ranges on its left and right.  Recursion
stops at the base case of a single element, which is by definition already
sorted.  Figure \ref{fig:algo:quick} illustrates each step in this
process\footnotemark, and listing \ref{lst:algo:quick} shows the implementation.
It is very concise since most of the actual work is done by utility functions.
The complexity of the entire operation is directly dependent on the partitioning
done in each recursive step:

\footnotetext{
    Conceptually, at least.  The implementation uses the empty range as the base
    case for simplicity.  In practice, sorting small arrays is done more
    efficiently with other methods, so implementations choose a critical length
    below which sorting is deferred to a different algorithm.
}

\begin{itemize}
    \item Ordering elements around the pivot is an $O(n)$ operation.
    \item
        The second factor depends on the point at which the range is
        partitioned:
        \begin{itemize}
            \item
                A perfect bisection reduces the range in half, thus sorting the
                entire range in $\log_2 n$ steps and yielding an overall
                complexity of $O(n \log n)$.
            \item
                Partitions which diverge from the median value increase the
                number of recursive steps.  The worst-case complexity is thus
                $O(n^2)$, which happens when the range is reduced by a single
                element in each step.
        \end{itemize}
\end{itemize}

Despite its worst-case complexity, carefully-chosen pivot selection and
partitioning methods\footnote{\cite{Bentley1993}} can result in very efficient
implementations.  Together with the fact that sorting is done in-place and
requires only a less-than operator makes it a common choice for standard
non-stable sorting functions.  This is the origin of the name of the
\texttt{qsort} function in the C standard library.
